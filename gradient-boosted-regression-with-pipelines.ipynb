{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are a convenient way to preprocess data and estimate a model with very few lines of code. The approach we will take is the following:\n",
    "- impute missing data (use mean for numerical values, most frequent for strings)\n",
    "- add one-hot encoded columns for categorical variables\n",
    "- run gradient-boosted regression using XGBoost and k-fold cross validation\n",
    "\n",
    "We will also use GridSearchCV to iterate through different parameter values to find the best performing model before generating our predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "X = pd.read_csv('../input/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "y = X.SalePrice\n",
    "X.drop(columns=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numerical_cols = [col for col in X.columns if (X[col].dtype == 'int64' or X[col].dtype == 'float64')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0), ['MSSubClass', 'LotFrontage', 'LotArea', 'O... reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'model__n_estimators': [2000, 3000], 'model__learning_rate': [0.01, 0.05], 'model__min_child_weight': [0, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_transformer = SimpleImputer()\n",
    "categorical_transformer = Pipeline(steps=\n",
    "                                   [('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=\n",
    "                                 [('num', numerical_transformer, numerical_cols), \n",
    "                                  ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "model = XGBRegressor(random_state=0)\n",
    "\n",
    "pipeline = Pipeline(steps=\n",
    "                   [('preprocess', preprocessor),\n",
    "                   ('model', model)])\n",
    "\n",
    "grid = GridSearchCV(pipeline,  \n",
    "                    param_grid={'model__n_estimators': [2000, 3000],\n",
    "                                'model__learning_rate' : [0.01, 0.05],                                \n",
    "                                'model__min_child_weight' : [0, 1]\n",
    "                               },\n",
    "                    cv = 10,\n",
    "                    scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'model__learning_rate': 0.05, 'model__min_child_weight': 0, 'model__n_estimators': 3000}\n",
      "Best score: 15184.293594820205\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model parameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {-1 * grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test predictions to file\n",
    "predictions = grid.predict(X_test)\n",
    "output = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
